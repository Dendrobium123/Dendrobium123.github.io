[{"content":"背景+摘要 图像作为视觉信息的主要传播媒介，在拍摄过程中常常会受到如雨、雾、雪等 外界因素的干扰，这些因素会显著降低图像的质量或掩盖关键信息，进而影响图像 的后续处理和应用。图像去雨便成为了亟需解决的问题，其主要挑战包括准确识别 各种大小和形状的雨滴，并在保持图像细节的同时去除这些干扰元素。因为除雨对于确保图像信息的准确传达至关重要，尤其是在交通监控和自动驾驶系统等对视觉精度要求较高的应用中。在雨天拍摄的未经处理的图像可能会导致视觉系统错误识别或遗漏关键信息，从而影响决策和操作的安全性和效率。\n在图像去雨的研究中，传统方法和基于深度学习的策略是两种主流技术。\n而随着深度学习今年 来在计算视觉领域的逐步应用，基于深度学习的去雨技术已成为近年来的研究热点。 这种方法利用大规模数据集对深度网络模型进行训练，然后将训练好的模型应用于 待处理的图像，从而有效地去除图像中的雨滴。\n本论文围绕对单画幅图像去雨展开研究，采用深度学习的方法，在PReNet算法 基础上提出了一种通过集成GAM注意力机制来增强去雨性能的新方法。PReNet是 一个高效的递归网络，专注于去除图像中的雨滴，但在处理复杂场景时仍存在一些 局限性。为了解决这一问题，本文在每个残差模块后引入了GAM注意力机制，通 过加强网络对有雨区域的感知能力，从而更精准地去除雨迹。本文在Rain100L和 Rain1400 等主流去雨数据集上进行了广泛的实验，实验结果显示，与原始PReNet模 型相比，集成了GAM注意力机制的新模型在峰值信噪比（PSNR）和结构相似性指 数（SSIM）上都有显著提高。结果证明了GAM注意力机制在去雨任务中的有效性 和潜在的应用价值。\nPReNet是什么 以下为PReNet论文原文：\n[1901.09221] Progressive Image Deraining Networks: A Better and Simpler Baseline (arxiv.org)\nPReNet是一种渐进递归网络，通过在基于ResNet的网络中引入递归层，以及将阶段性结果和原始多雨图像作为每个ResNet的输入，来提高去雨的性能。该网络能够有效地去除雨滴，对于图像去雨领域的研究具有重要意义，并可作为未来图像去雨研究的合适基础。\nPReNet，全称为Progressive Recurrent Network，是一个专门为单图像去雨任务设计的深度学习架构。这种网络采用了递归神经网络的设计思想，通过逐步精细化的方式去除图像中的雨滴，逐渐恢复干净的背景图像。本文选取PReNet模型作为图像去雨算法的基本框架，接下来对PReNet网络结构进行介绍。\nPReNet结构 (1) 输入层 输入卷积层由一个核大小为3*3、填充大小为1的标准卷积层构成，其后跟随有ReLU非线性激活函数,该层输入为6通道,输出为32通道。\n1 2 3 4 (conv0): Sequential( (0): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU() ) (2) 循环层 循环层使用的是LSTM(Long short-term memory),LSTM结构有两个传输状态$c^t$和$h^t$。通过前一个阶段传递下来的状态 $h^{t-1}$以及当前的输入状态 $x^t$拼接训练得到四个状态。LSTM的内部结构如下图所示,图中第一个公式得到的$c^t$是传给下一个阶段的状态，$h^t$表示该阶段的隐藏状态，$y^t$表示输出。 ⊙表示表示矩阵中对应元素相乘的操作,而相乘的两个矩阵为同型矩阵,⊕表示矩阵加法操作。LSTM结构内部有忘记、选择记忆和输出这三个阶段。\nLSTM的输入为64通道，输出为32通道,卷积核大小为3*3,填充大小为1。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 (conv_i): Sequential( (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): Sigmoid() ) (conv_f): Sequential( (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): Sigmoid() ) (conv_g): Sequential( (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): Tanh() ) (conv_o): Sequential( (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): Sigmoid() ) (3) ResBlocks ResBlocks是通过递归展开一个残差块5次来实现的。每个这样的残差块包括两个普通的卷积层，每层后接一个ReLU激活函数,ResBlocks中的每个卷积层输入输出通道数均为32,核大小为3*3,填充大小为1。整个ResBlocks的结构如图3.2所示,图中的5个ResBlock具有相同结构,且参数共享。而单个残差块以残差块1为例，结构如下方代码所示。由于整个模型网络参数主要来自ResBlocks,因此使得模型整体大小由于重复计算而显著减小。\n1 2 3 4 5 6 (res_conv1): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU() (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU() ) (4) 输出层 输出层是由一个核大小为3*3的标准卷积层构成,填充大小为1,输入为32通道,输出为3通道。\n1 2 3 (conv): Sequential( (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (5) 损失函数 在网络训练方面,PReNet使用了负结构相似性(-SSIM)损失函数。\n(6) 总体结构 PReNet模型的6个阶段共享相同的网络参数,将一个ResBlock在一个阶段内反复展开5次,以显著减少网络的参数。PReNet模型包含四个部分:输入卷积层、循环层、ResBlocks和输出卷积层,其整体结构如图3.3所示,左边的图为单个阶段的具体结构,右边图为PReNet模型的整体结构。PReNet模型阶段t的结构的推导公式如下: $$ x^{t-0.5} =f_{\\text{in}}(x^{t-1}, y), \\\\ s^t = f_{\\text{recurrent}}(s^{t-1}, x^{t-0.5}), \\\\ x^t = f_{\\text{out}}(f_{\\text{res}}(s_t)). $$ 其中, $f_{\\text{in}}$$x^{t-1} $和待去雨图像 y 的拼接结果,第一阶段的输入是两个待去雨图像的拼接, $x^{t-0.5}$ 即为输入层的输出, $s^{t-1}$为上一阶段循环层$LSTM$ 传递过来的信息,$f_{\\text{recurrent}} $ 表示循环层的作用,$s^t$表示当前阶段循环层的输出,$f_{\\text{res}}$表示$Resblocks$, $f_{\\text{out}} $表示输出层, $x^t$表示当前阶段的去雨结果。\nGAM模块 论文《Global Attention Mechanism: Retain Information to Enhance Channel-Spatial Interactions》\n[2112.05561] Global Attention Mechanism: Retain Information to Enhance Channel-Spatial Interactions(arxiv.org)\n1、作用 这篇论文提出了全局注意力机制（Global Attention Mechanism, GAM），旨在通过保留通道和空间方面的信息来增强跨维度交互，从而提升深度神经网络的性能。GAM通过引入3D排列与多层感知器（MLP）用于通道注意力，并辅以卷积空间注意力子模块，提高了图像分类任务的表现。该方法在CIFAR-100和ImageNet-1K数据集上的图像分类任务中均稳定地超越了几种最新的注意力机制，包括在ResNet和轻量级MobileNet模型上的应用。\n2、机制 $$ F_2 = M_c(F_1) \\otimes F_1 \\\\ F_3 = M_s(F_2) \\otimes F_2 $$ 1、通道注意力子模块：\n利用3D排列保留跨三个维度的信息，并通过两层MLP放大跨维度的通道-空间依赖性。这个子模块通过编码器-解码器结构，以一个缩减比例r（与BAM相同）来实现。\n2、空间注意力子模块：\n为了聚焦空间信息，使用了两个卷积层进行空间信息的融合。同时，为了进一步保留特征图，移除了池化操作。此外，为了避免参数数量显著增加，当应用于ResNet50时，采用了分组卷积与通道混洗。\n3、独特优势 1、效率与灵活性：\nGAM展示了与现有的高效SR方法相比，如IMDN，其模型大小小了3倍，同时实现了可比的性能，展现了在内存使用上的高效性。\n2、动态空间调制：\n通过利用独立学习的多尺度特征表示并动态地进行空间调制，GAM能够高效地聚合特征，提升重建性能，同时保持低计算和存储成本。\n3、有效整合局部和非局部特征：\nGAM通过其层和CCM的结合，有效地整合了局部和非局部特征信息，实现了更精确的图像超分辨率重建。\n4、代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 import torch.nn as nn import torch class GAM_Attention(nn.Module): def __init__(self, in_channels, rate=4): super(GAM_Attention, self).__init__() # 通道注意力子模块 self.channel_attention = nn.Sequential( # 降维，减少参数数量和计算复杂度 nn.Linear(in_channels, int(in_channels / rate)), nn.ReLU(inplace=True), # 非线性激活 # 升维，恢复到原始通道数 nn.Linear(int(in_channels / rate), in_channels) ) # 空间注意力子模块 self.spatial_attention = nn.Sequential( # 使用7x7卷积核进行空间特征的降维处理 nn.Conv2d(in_channels, int(in_channels / rate), kernel_size=7, padding=3), nn.BatchNorm2d(int(in_channels / rate)), # 批归一化，加速收敛，提升稳定性 nn.ReLU(inplace=True), # 非线性激活 # 使用7x7卷积核进行空间特征的升维处理 nn.Conv2d(int(in_channels / rate), in_channels, kernel_size=7, padding=3), nn.BatchNorm2d(in_channels) # 批归一化 ) def forward(self, x): b, c, h, w = x.shape # 输入张量的维度信息 # 调整张量形状以适配通道注意力处理 x_permute = x.permute(0, 2, 3, 1).view(b, -1, c) # 应用通道注意力，并恢复原始张量形状 x_att_permute = self.channel_attention(x_permute).view(b, h, w, c) # 生成通道注意力图 x_channel_att = x_att_permute.permute(0, 3, 1, 2).sigmoid() # 应用通道注意力图进行特征加权 x = x * x_channel_att # 生成空间注意力图并应用进行特征加权 x_spatial_att = self.spatial_attention(x).sigmoid() out = x * x_spatial_att return out # 示例代码：使用GAM_Attention对一个随机初始化的张量进行处理 if __name__ == \u0026#39;__main__\u0026#39;: x = torch.randn(1, 64, 20, 20) # 随机生成输入张量 b, c, h, w = x.shape # 获取输入张量的维度信息 net = GAM_Attention(in_channels=c) # 实例化GAM_Attention模块 y = net(x) # 通过GAM_Attention模块处理输入张量 print(y.shape) # 打印输出张量的维度信息 SE Net模块 论文《Squeeze-and-Excitation Networks》\n[1709.01507] Squeeze-and-Excitation Networks(arxiv.org)\n1、作用 SE 模块通过引入一个新的结构单元——“Squeeze-and-Excitation”（SE）块——来增强卷积神经网络的代表能力。是提高卷积神经网络（CNN）的表征能力，通过显式地建模卷积特征通道之间的依赖关系，从而在几乎不增加计算成本的情况下显著提升网络性能。SE模块由两个主要操作组成：压缩（Squeeze）和激励（Excitation）\n2、机制 1、压缩操作：\nSE模块首先通过全局平均池化操作对输入特征图的空间维度（高度H和宽度W）进行聚合，为每个通道生成一个通道描述符。这一步有效地将全局空间信息压缩成一个通道向量，捕获了通道特征响应的全局分布。这一全局信息对于接下来的重新校准过程至关重要。\n2、激励操作：\n在压缩步骤之后，应用一个激励机制，该机制本质上是由两个全连接（FC）层和一个非线性激活函数（通常是sigmoid）组成的自门控机制。第一个FC层降低了通道描述符的维度，应用ReLU非线性激活，随后第二个FC层将其投影回原始通道维度。这个过程建模了通道间的非线性交互，并产生了一组通道权重。\n3、特征重新校准：\n激励操作的输出用于重新校准原始输入特征图。输入特征图的每个通道都由激励输出中对应的标量进行缩放。这一步骤有选择地强调信息丰富的特征，同时抑制不太有用的特征，使模型能够专注于任务中最相关的特征。\n3、独特优势 1、通道间依赖的显式建模：\nSE Net的核心贡献是通过SE块显式建模通道间的依赖关系，有效地提升了网络对不同通道特征重要性的适应性和敏感性。这种方法允许网络学会动态地调整各个通道的特征响应，以增强有用的特征并抑制不那么重要的特征。\n2、轻量级且高效：\n尽管SE块为网络引入了额外的计算，但其设计非常高效，额外的参数量和计算量相对较小。这意味着SENet可以在几乎不影响模型大小和推理速度的情况下，显著提升模型性能。\n3、模块化和灵活性：\nSE块可以视为一个模块，轻松插入到现有CNN架构中的任何位置，包括ResNet、Inception和VGG等流行模型。这种模块化设计提供了极大的灵活性，使得SENet可以广泛应用于各种架构和任务中，无需对原始网络架构进行大幅度修改。\n4、跨任务和跨数据集的泛化能力：\nSENet在多个基准数据集上展现出了优异的性能，包括图像分类、目标检测和语义分割等多个视觉任务。这表明SE块不仅能提升特定任务的性能，还具有良好的泛化能力，能够跨任务和跨数据集提升模型的效果。\n5、增强的特征表征能力：\n通过调整通道特征的重要性，SENet能够更有效地利用模型的特征表征能力。这种增强的表征能力使得模型能够在更细粒度上理解图像内容，从而提高决策的准确性和鲁棒性。\n4、代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 import numpy as np import torch from torch import nn from torch.nn import init class SEAttention(nn.Module): # 初始化SE模块，channel为通道数，reduction为降维比率 def __init__(self, channel=512, reduction=16): super().__init__() self.avg_pool = nn.AdaptiveAvgPool2d(1) # 自适应平均池化层，将特征图的空间维度压缩为1x1 self.fc = nn.Sequential( # 定义两个全连接层作为激励操作，通过降维和升维调整通道重要性 nn.Linear(channel, channel // reduction, bias=False), # 降维，减少参数数量和计算量 nn.ReLU(inplace=True), # ReLU激活函数，引入非线性 nn.Linear(channel // reduction, channel, bias=False), # 升维，恢复到原始通道数 nn.Sigmoid() # Sigmoid激活函数，输出每个通道的重要性系数 ) # 权重初始化方法 def init_weights(self): for m in self.modules(): # 遍历模块中的所有子模块 if isinstance(m, nn.Conv2d): # 对于卷积层 init.kaiming_normal_(m.weight, mode=\u0026#39;fan_out\u0026#39;) # 使用Kaiming初始化方法初始化权重 if m.bias is not None: init.constant_(m.bias, 0) # 如果有偏置项，则初始化为0 elif isinstance(m, nn.BatchNorm2d): # 对于批归一化层 init.constant_(m.weight, 1) # 权重初始化为1 init.constant_(m.bias, 0) # 偏置初始化为0 elif isinstance(m, nn.Linear): # 对于全连接层 init.normal_(m.weight, std=0.001) # 权重使用正态分布初始化 if m.bias is not None: init.constant_(m.bias, 0) # 偏置初始化为0 # 前向传播方法 def forward(self, x): b, c, _, _ = x.size() # 获取输入x的批量大小b和通道数c y = self.avg_pool(x).view(b, c) # 通过自适应平均池化层后，调整形状以匹配全连接层的输入 y = self.fc(y).view(b, c, 1, 1) # 通过全连接层计算通道重要性，调整形状以匹配原始特征图的形状 return x * y.expand_as(x) # 将通道重要性系数应用到原始特征图上，进行特征重新校准 # 示例使用 if __name__ == \u0026#39;__main__\u0026#39;: input = torch.randn(50, 512, 7, 7) # 随机生成一个输入特征图 se = SEAttention(channel=512, reduction=8) # 实例化SE模块，设置降维比率为8 output = se(input) # 将输入特征图通过SE模块进行处理 print(output.shape) # 打印处理后的特征图形状，验证SE模块的作用 消融实验ablation 实验环境 本文的实验平台为64位windows11系统，GPU为NVIDIA GeForce RTX 4070(12GB/华硕)，搭配的处理器为intel i5-13490F。Anaconda版本为23.7.4。cuda版本为12.1。Pytorch版本2.1.2。Python版本为3.9.18。tensorboard版本为2.16.2。\n本实验中所有的网络都使用相同的训练设置,填充大小是100*100,batchsize大小是18,本文使用优化器为ADAM来训练模型,对Rain100L数据集的训练周期为100个epoch(对于其他大数据集如Rain1400等由于时间问题，并没有达到这个迭代周期),初始学习率设置为0.001,当epoch分别为30、50、80时,学习率均乘以0.2。\n评估指标 本文使用图像去雨领域常用的图像质量评价指标PSNR、SSIM来对算法进行有效评估与比较。\n峰值信噪比PSNR PSNR 的计算基于均方误差（MSE）。首先计算 MSE，它是原始图像和失真图像对应像素差的平方值的平均值。PSNR的值越高表示处理后的图像与原图越接近。PSNR通过下面的公式计算：\n​ $$ PSNR = 10\\cdot\\log_{10}\\left(\\frac{{MAX}^2}{{MSE}}\\right) $$ 其中，$\\text{MAX}$是可能的最大像素值，通常对于8位图像是255，$\\text{MSE}$（Mean Squared Error）表示均方误差。而MSE的计算方式如下：\n$$ MSE = \\frac{1}{mn} \\sum_{i=1}^m \\sum_{j=1}^n(I(i, j) - K(i, j))^2 $$ 其中，$m$ 和 $n$ 分别是图像的行数和列数，$I(i, j)$ 是原始图像在位置 $(i, j)$ 的像素值，$K(i, j)$ 是失真或重建图像在位置 $(i, j)$ 的像素值。\n结构相似性SSIM SSIM基于三个比较维度：亮度（luminance）、对比度（contrast）和结构（structure）。SSIM指数通过比较两幅图像的亮度、对比度和结构的相似性来计算。SSIM的值范围从-1到1，其中1表示两图像完全相同。其计算方式如下：\n$$ \\text{SSIM}(x, y) = \\left( \\frac{2 \\mu_x \\mu_y + C_1}{\\mu_x^2 + \\mu_y^2 + C_1} \\right) \\times \\left( \\frac{2 \\sigma_{xy} + C_2}{\\sigma_x^2 + \\sigma_y^2 + C_2} \\right) \\times \\left( \\frac{\\sigma_{xy} + C_3}{\\sigma_x \\sigma_y + C_3} \\right) $$\n其中 $\\mu_x$ 和 $\\mu_y$ 分别是图像 $x$ 和 $y$ 的平均亮度。 $\\sigma_x^2$ 和 $\\sigma_y^2$ 分别是图像 $x$ 和 $y$ 的方差。 $\\sigma_{xy}$ 是图像 $x$ 和 $y$ 的协方差。 $C_1, C_2, C_3$ 是小常数，用以维持稳定性，通常 $C_3 = \\frac{C_2}{2}$。\n实验数据集 本文的所有的消融实验都是在合成的小雨数据集Rain100L上进行的，Rain100L数据集里面包含有雨图片和对应的无雨图片,雨纹的密度较小,其训练集有200张有雨图片,测试集有100张有雨图片。对比实验在Rain100L，Rain1400以及Rain12上进行。\n损失函数 本文的loss function选择与原PReNet论文一直，采用negative SSIM作为loss，通过取负，我们可以将最大化SSIM的问题转化为最小化负SSIM的问题从而符合求最小损失这个前提。且ssim的评估方式更符合人眼直觉。本loss function表达式为： $$ L_s=-SSIM $$\n我在第一层卷积层后缝合了gam模块\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class PReNet(nn.Module): def __init__(self, recurrent_iter=6, use_GPU=True): super(PReNet, self).__init__() self.iteration = recurrent_iter self.use_GPU = use_GPU ... ... ... self.gam=GAM_Attention(in_channels=32)#GAM def forward(self, input): batch_size, row, col = input.size(0), input.size(2), input.size(3) ... ... for i in range(self.iteration): x = torch.cat((input, x), 1) x = self.conv0(x) x = self.gam(x) x = torch.cat((x, h), 1) ... ... return x, x_list 实验设计 本部分通过引入SE通道注意力机制模块以及GAM全局注意力机制模块，分别安插在PReNet网络的不同位置进行性能比对，从而筛选出更优质的改进方案。嵌入位置如下图：\n对于不同注意力模块以及其在网络中嵌入的不同位置，后以不同名字指代如表1.1所示。\n注意力模块的相对位置 后续的网络命名 GAM模块在残差块内 PReNet_GAM_R SE 模块在残差块内 PReNet_SE_R GAM模块在输入层后 PReNet_GAM_afterConv0 SE 模块在输入层后 PReNet_SE_afterConv0 GAM模块在输入层后，SE模块在残差块内 PReNet_GAM_SE SE 模块在输入层后，GAM模块在残差块内 PReNet_SE_GAM GAM模块同时在输入层后以及残差块内 PReNet_GAM_GAM 在Rain100L上的消融实验结果 模型名称 PSNR SSIM PReNet 37.48 0.979 PReNet_GAM_R 37.97 0.980 PReNet_SE_R 37.69 0.979 PReNet_GAM_afterConv0 37.49 0.979 PReNet_SE_afterConv0 37.49 0.979 PReNet_GAM_SE 37.45 0.979 PReNet_SE_GAM 37.92 0.981 PReNet_GAM_GAM 37.91 0.980 针对Rain100L数据集的实验结果表明，当GAM模 块单独集成在每个残差块内时，网络性能提升最为明显。这一发现表明GAM模块在 处理图像中的全局信息方面具有显著优势，能够有效地提升去雨效果。\n对比实验 将上文所提的PReNet_GAM_R方案在Rain1400、Rain100L和Rain12这 三个合成数据集上与3种经典的基于深度学习的图像去雨算法JORDER、RESCAN、 PReNet 算法以及本文提的PReNet_GAM_R方案进行定性定量评估比较。\n并在真实雨 图上进行主观感觉上的比较,来验证本方案的有效性。\n(1) 合成数据集 本文方案与上述4种去雨算法的定量比较如表4.6所示,红色标注即为最高值。 从表中可以看出,PReNet_GAM_R方案在三个合成数据集上均能取得较高的PSNR和 SSIM 指标值,且其在三个合成数据集上的指标值基本高于其他四个去雨算法。 需要说明的是本对比实验中，PReNet_GAM_R 针对 Rain1400 数据集的训练 epoch 仅为 8 个 epochs，主要原因为 Rain1400 数据集庞大从而导致训练时间长的 问题，在RTX4070显卡夜以继日地连续72小时的工作情况下也仅仅训练到了第8 个epoch，因此此处的对比数据比原先PReNet性能略低一筹。\nDataset Measure JORDER RESCAN PReNet PReNet_GAM_R Rain100L PSNR/SSIM 36.61/0.974 29.80/0.881 37.48/0.979 37.97/0.980 Rain12 PSNR/SSIM 33.92/0.953 \u0026mdash;\u0026ndash; 36.66/0.961 37.04/0.962 Rain1400 PSNR/SSIM \u0026mdash;\u0026ndash; \u0026mdash;\u0026ndash; 32.60/0.946 32.41/0.945 (2) 真实雨图 接下来将改进的PReNet_GAM_R与原先的PReNet在真实雨图上的去雨效果进 行比对，如下方图所示，从左到右依次为原始图像，PReNet图像，PReNet_GAM_R 图像，从上到下一共展示三组真实雨图，此处所用于测试的模型为在Rain1400数据 集上训练8epochs的PReNet_GAM_R网络 。\n通过观察可以发现，PReNet_GAM_R改进后的去雨图像在清晰度上比PReNet的 去雨图像更为清晰，在细节部分没有出现丢失的情况，整幅图片看起来更为透彻，在 图像的清晰度提高和细节保留更完整，从而提供了更加令人满意的视觉效果。此外， 从感官体验的角度来看，图像的细节，如建筑线条、环境纹理和边缘清晰度等，在去 除雨水后都被更好地保留了下来，几乎与无雨的原始场景无异。\n最后的网络结构 总结与展望 总结 本文介绍了在PReNet网络中集成不同的注意力机制模块的融合实验。通过详细的实验设计，分析了SE和GAM模块单独插入原网络输入层后和残差块内的效果，还考察了这两种模块同时使用时的性能变化。实验结果通过PSNR和 SSIM 指标进行量化，以评估不同配置对去雨效果的影响。针对Rain100L数据集的 实验结果表明，当GAM模块单独集成在每个残差块内时，网络性能提升最为明显。 本文的研究表明，注意力机制，尤其是全局注意力机制在提高深度网络处理复 杂去雨任务中的有效性。GAM模块通过其对全局信息的高效整合，使得网络能够更 准确地识别和去除图像中的雨滴，同时保留更多的背景细节。这一点在图像去雨的应用中尤为重要，因为背景信息的保留直接关系到去雨图像的视觉质量和实用价值。\n展望 本文改进的GAM融合PReNet去雨算法在进行单幅图像去雨工作时有一定的 提升效果,但与最新发布的去雨研究相比，仍存在一定的差距。此外，受限于硬件 资源和时间成本，本研究未能对多个大型数据集进行深入分析，甚至在唯一使用的 Rain1400 数据集上的训练周期也仅限于8个epochs。这些限制使得研究结果可能未 能完全体现潜在的优化效果。因此，未来研究的方向和展望可以从以下几个方面进 行扩展和深化：\n(1) 本文已经尝试了集成不同的注意力机制以优化去雨性能。未来工作可以继续 在这一方向上进行创新，例如探索新的神经网络架构或改进现有的深度学习模块，以适应去雨处理的特定需求。此外，调整和优化模型参数也是实现更有效去雨处理的 关键途径。\n(2) 尽管通过合成的虚拟雨图可以以更多样本地进行全监督学习，但这些数据往 往无法完全复现真实雨景的复杂性和多样性。因此，开发和使用更接近真实世界条 件的雨图数据集将是未来研究的重要方向。这将帮助模型更好地理解和处理实际场 景中的雨效应，提高去雨技术的实际应用价值。\n(3) 目前常用的图像质量评估指标如PSNR和SSIM虽然提供了量化的性能评估， 但并不能完全代表人类的视觉感知。应该设计一种更符合人类视觉感知的评价方法， 能更准确地反映去雨效果的优劣，这对于推动去雨技术的发展具有重要意义。\n(4) 考虑到降雨的复杂性，将模型驱动方法与数据驱动方法结合起来，可能是解 决去雨问题的一种有效策略。这种融合方法可以充分利用两种学习方式的优势，提高去雨算法的准确性和鲁棒性。 希望未来通过在上述几方面的努力，可以使得去雨研究有望实现更大的突破，为相关领域带来更深远的影响。\n写在最后的ps 所谓的毕设就这么莫名其妙的搞完了，其实工作量很小，多半的工作量是前期阅读论文以及复现各种其他的去雨算法来选择一个比较合适的改进平台，后期所有的实验基本上只花了几天的功夫，反正现在答辩也弄完了，后面空闲的时间可能会做几个开源项目，然后再次投入那场“永恒轮回”的地狱中。\n复旦get out，中科院 come instead！\n","date":"2024-05-24T13:10:42+08:00","image":"http://tuchuang.dendrobiumcgk.chat/pic/image-20240524215731380.png","permalink":"https://Dendrobium123.github.io/p/%E5%9F%BA%E4%BA%8Eprenet%E6%B8%90%E8%BF%91%E9%80%92%E5%BD%92%E7%BD%91%E7%BB%9C%E4%B8%8Egam%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%A8/","title":"基于PReNet渐近递归网络与gam注意力机制的图像去雨"},{"content":"火焰战士 不知从何时起我开始觉得天空好美，\n可能是因为那个少女消失在那里的缘故吧，\n我有些羡慕她，\n没有翅膀的我，\n只有将希望和憧憬寄托在她的身上，\n在天空中飞翔的她，能够感受到我的思念吗？\n天空不再是遥不可及，\n她一定把我的梦想带上了天际，\n我坚信。\n不知从何时起，\n我一直在做一个梦，\n一遍又一遍，\n没有开始也没有终结，\n我暗自祈祷这不是梦，\n因为梦总会结束，\n于是我开始等待，\n等待着某人将我唤醒，\n我仿佛坐在空无一人的山顶上，\n听着一个脚步声由远而近，\n也许那之后才是梦的开始，\n仿佛时间已经停止，\n我一直在等待着，\n直到我已经忘记了，\n为何要等待，\n但是正如黑夜之后一定是黎明，\n奇迹一定会到来，\n我坚信\n","date":"2024-05-17T13:10:42+08:00","image":"http://tuchuang.dendrobiumcgk.chat/pic/image-20240517233703783.png","permalink":"https://Dendrobium123.github.io/p/%E6%97%B6%E9%97%B4%E7%9A%84%E8%BD%AE%E5%BB%93/","title":"时间的轮廓"},{"content":"PyTorch基础笔记_01 常用库：torch，numpy，pandas，matplotlib\n1 2 3 4 5 import torch import numpy as np import torch.nn as nn from torch import optim as optim#优化器 import torch.nn.functional as F#用到的函数 基础使用 假设一个最简单的神经网络，没有隐藏层，只有输入层和输出层\neg：5个输入神经元，7个输出神经元，全连接 $$ y=w\\cdot x+b $$ x为输入层，形状为（1,5）； $$ \\begin{bmatrix}x_1 \u0026amp; x_2\u0026amp;x_3\u0026amp;x_4\u0026amp;x_5\\end{bmatrix} $$ Y为输出层，形状为（1,7）#同上 $$ \\begin{bmatrix}y_1 \u0026amp; y_2\u0026amp;y_3\u0026amp;y_4\u0026amp;y_5\u0026amp;y_6\u0026amp;y_7\\end{bmatrix} $$ w为权重，形状为（5,7) #全连接， $$ \\begin{bmatrix}w_{11}\u0026amp;w_{12}\u0026amp;w_{13}\u0026amp;w_{14}\u0026amp;w_{15}\u0026amp;w_{16}\u0026amp;w_{17} \\\\w_{21} \u0026amp; w_{22}\u0026amp;w_{23}\u0026amp;w_{24}\u0026amp;w_{25}\u0026amp;w_{26}\u0026amp;w_{27} \\\\w_{31} \u0026amp; w_{32}\u0026amp;w_{33}\u0026amp;w_{34}\u0026amp;w_{35}\u0026amp;w_{36}\u0026amp;w_{37} \\\\w_{41} \u0026amp; w_{42}\u0026amp;w_{43}\u0026amp;w_{44}\u0026amp;w_{45}\u0026amp;w_{46}\u0026amp;w_{47} \\\\w_{51} \u0026amp; w_{52}\u0026amp;w_{53}\u0026amp;w_{54}\u0026amp;w_{55}\u0026amp;w_{56}\u0026amp;w_{57} \\end{bmatrix} $$ b为bias偏置，每个输出神经元输出前都会经过bias调整，所以形状为7\n1 2 3 4 5 6 7 8 9 10 11 12 13 #定义各个参数 w=torch.randn(5,7,requires_grad=True)#生成5*7的随机数矩阵来填充w,同时设定w是需要后续进行梯度下降更新的属性，后半部分缺失会导致程序报错 b=torch.randn(7,requires_grad=True) x=torch.randn(1,5) Y=torch.randn(1,7) lr=0.001#设置学习率 y=F.relu(x @ w + b) #x与w为矩阵，使用矩阵乘法@,同时调用事前导入为F的激活函数，这里选择relu函数（1） #开始求loss，假定本案例为一个分类任务，选择交叉熵损失函数 loss=F.cross_entropy(y,Y) #开始求参数梯度，进行梯度下降算法更新参数，pytorch提供了一个函数方法backward()，可以直接帮助我们找到所有参数梯度，无需自己算 loss.backward()#这步只求了梯度，顺利运行的前提是需要提前设定参数是需要求梯度的属性 w.grad#查看w经过梯度下降所得的参数值，！还没有进行参数的更新！见（2） w=w -lr * w.grad#这步才是更新了参数（3） 两种损失函数 1.分类任务一般使用交叉熵损失函数：\n$$ \\text{Cross-Entropy}= -\\sum_{i=1}^n [y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i)] \\\\y_i：\\text{ 类别的真实标签（通常为0或1）} \\\\\\hat{y_i}: \\text{对应类别的预测概率} $$\n2.回归任务一般使用均方误差损失函数\n$$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 \\\\y_i：\\text{真实值} \\\\\\hat{y_i}:预测值 \\\\n:样本数量 $$ 损失函数使用时需注意该函数的传参\n（1）结果：\n（2）结果：\n（3）结果：\n搭建模型 搭建网络需要定义一个类，eg此处输入图像为rgb彩色图像，像素为48*48\nps: jupyter lab查看函数参数快捷键shift+tab\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class M_CNN(nn.Module):#定义网络，父类为之前导入的nn类 def __init__(self):#初始化 super().__init__()#父类的函数方法 self.conv1 =nn.Conv2d(3,16,kernel_size=3,padding=1)#设计的卷积层，调用nn父类中的Conv2d卷积函数，参数见（4）eg：输入为彩色图像（输入为3），输出16个通道，卷积核大小为3*3；padding=1为填充1像素保证输出的长宽不变 self.conv2 =nn.Conv2d(16,32,kernel_size=3,padding=1) self.bn1=nn.BatchNorm2d(16)#规范化，通道数为16#第一层卷积的输出通道数 self.bn2=nn.BatchNorm2d(32) self.MaxPool=nn.MaxPool2d(kernel_size=2)#池化层 self.fc1=nn.Linear(12*12*32,1000)#网络全连接层，将处理完的输入图像所有像素拼接为一维，加入中间有1000个神经元的隐藏层 self.fc2=nn.Linear(1000,100)#1000个隐藏层1神经元，最送到100个隐藏层2神经元，由于12*12*32的输入太大，故需要不同神经元数目的隐藏层过渡 self.fc3=nn.Linear(100,7)#最后输出为7个神经元 def forward(self,x): x=F.relu(self.bn1(self.conv1(x)))#输入先过卷积，后过规范器，最后通过激活函数relu，更新原有输入 x=self.MaxPool(x)#经过池化后图像宽高对半减 x=F.relu(self.bn2(self.conv2(x)))#经过第二个卷积层 x=self.MaxPool(x) x=x.view(-1,12*12*32)#进入全连接之前，需要讲3维张量撑成1维的向量，-1代表可能用小批量进行训练，不确定数目，代表自适应，后面的数值代表进入的张量 x=F.relu(self.fc1(x))#进入全连接 x=F.relu(self.fc2(x)) x=F.relu(self.fc3(x)) return x 全连接层参数计算： $$ 一个(3,48\\times48)图像通过一个(3,16,kernel=3\\times3,步长为1)的卷积层，\\\\输出为(16,48\\times48)图像，\\\\通过第一个池化层，窗口为2\\times2,步长为2，\\\\输出为(16，24\\times24),\\\\经过第二个卷积层(16，32，kernel=3\\times3,步长为1)\\\\输出为(32,24\\times24)，\\\\通过第二个池化层，变为(32，12\\times12) $$\n（4）nn.Conv2d函数的参数：\n数据处理 读取数据，转化为dataset，再由dataset转化为dataloader\n1 2 3 4 5 6 7 8 9 from torch.utils.data import DataLoader from torchvision import datasets,tranforms from torchvision.datasets import ImageFolder transform=transforms.Compose([ transforms.ToTensor()#读取图像后将数据转换为tensor类型 transforms.Normalize(mean=(0.5,),std=(0.5,))#去均值，除标准差的归一化操作 ]) dataset=ImageFolder(\u0026#39;file_path\u0026#39;,tansform=transform)#通过imagefolder来为读取的数据进行标注，后半部分使用tranform进行格式转化 dataloader=DataLoader(dataset,batch_size=32,shuffle=True)#shuffle意义为每个batch开始时顺序是否要被打乱 跑模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #检测GPU使用情况 device=torch.device(\u0026#39;cuda:0\u0026#39; if torch.cuda.is_available() else \u0026#39;cpu\u0026#39;) print(\u0026#39;Using device\u0026#39;,device) #创建模型 model=CNN_M().to(device) #定义损失函数 loss_fun=F.cross_entropy #定义优化器 opt=optim.Adam(model.parameters(),lr=0.01)#parameters为模型的所有参数 epochs=8#以batchsize为32的步长，每个批次通过一遍网络，直至所有样本被扫完作为一个epoch for epoch in range(epochs): for i,data in enumerate(dataloader,0):#每次的小batch做的事 inputs,labels=data[0].to(device),data[1].to(device)#input为作为输入的数据，labels为获取标签，to(device)为把数据往显卡里送 y=model(inputs)#进入模型的forward第一层到最后一层，结果给y loss=F.cross_entropy(y,labels)#通过计算得的y与labels标签正确答案进行损失计算 loss.backward()#计算梯度值 opt.step()#优化器进行梯度下降，更新参数 opt.zero_grad()#参数的梯度清零，不然进入下一轮梯度计算时会累积上一次的结果 print(i,loss) ps:最后来一张之前tutu带我看的不认识的Vtuber演唱会 ","date":"2024-04-18T21:02:02+08:00","image":"http://tuchuang.dendrobiumcgk.chat/pic/pytorch_0.jpg","permalink":"https://Dendrobium123.github.io/p/pytorch%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0_01/","title":"PyTorch基础笔记_01"},{"content":"\r深度学习基础知识 几种“学习”间的关系\n机器学习\u0026mdash;最大的概念 \u0026lt;让机器通过学习的方式得到一个可以解决问题的模型\u0026gt;\n学习方法：KNN（K近邻），k means（k均值解决聚类问题），SVM，深度学习\n机器学习，隐式学习\n神经网络：输入层，隐藏层，输出层\n神经元\n不改变网络层和算法的情况下，影响输出结果的是各神经元连接线路上的数值权重\n除了一系列加减乘除的线性变换外，还引入了激活函数\n激活函数：阶跃函数（不用 希望通过梯度下降的方式求得参数更新的过程，阶跃函数无法正常求导，需要引入δ函数，因此使用别的函数作为激活函数Sigmoid，以此解决阶跃函数不可导的问题\nSigmoid： $$ S(x)=\\dfrac{1}{1+e^{-x}} $$\nsigmoid导数： $$ S\u0026rsquo;(x)=\\dfrac{e^{-x}}{(1+e^{-x})^2}=S(x)(1-S(x)) $$ Sigmoid函数及其导数的图像：\n注：取值范围在0—1间的sigmoid函数叫logistic函数\rtanh： $$ tanh=\\dfrac{e^x-e^{-x}}{e^x+e^{-x}} $$\n范围在（-1，1）间的激活函数\nRelu函数 $$ f(x)=\\begin{cases}x \u0026amp; x\\geq0 \\\\0\u0026amp;x\u0026lt; 0\\end{cases} $$\n每个神经元所做的事： $$ g_{output}=g(w_1\\times a+w_2\\times b+w_3\\times c+w_4\\times d)—\u0026gt;relu $$ 注：a,b,c,d为权重值，神经元输出结果为各参数加权后通过一个relu函数所得的值\n机器学习的目的是在给定前提情况下，寻找能得到最好输出的w参数们\n梯度下降 如何寻找需要的W\n通过当前所计算得出的结果与已知的正确结果做差，考虑到所得结果的正负号问题，采用对式子求平方的方式（平方好求导，绝对值不好求导） $$ L=(f(x)-y)^2 $$\nL越小，模型性能越好，f(x)与参数w有关，因此L也是个关于w的函数。\n可以通过调整w来使L的取值变小\n动态更新W，eg：初始值w0，第一刻w1\u0026hellip;.. $$ W_1=W_0-lr\\cdot \\frac{\\partial L}{\\partial W_0} \\\\W_2=W_1-lr\\cdot \\frac{\\partial L}{\\partial W_1} \\\\\u0026hellip; $$\n局部最优/全局最优 类似高等数学函数章节中的极值和最值问题，局部导数为0的极值点不代表此处是整个函数的极值\n~~乐经良：说明它是一个地头蛇~~\rps:顺带吐槽一句，这个hugo对LateX数学公式的键入好像不是很友好，比如公式间的换行用要用\\\\，但是他识别代码的时候只识别一条杠\\，这就导致像 $$ f(x)=\\begin{cases}x \u0026amp; x\\geq0 \\\\0\u0026amp;x\u0026lt; 0\\end{cases} $$ 这种分段的函数会显示成这样 $$ f(x)=\\begin{cases}x \u0026amp; x\\geq0 \\0\u0026amp;x\u0026lt; 0\\end{cases} $$\nbyd后来我发现你只需要打3个\\就能解决问题了。\n","date":"2024-04-14T12:20:50+08:00","image":"http://tuchuang.dendrobiumcgk.chat/pic/深度学习00cover.jpg","permalink":"https://Dendrobium123.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_00/","title":"深度学习_00"},{"content":"这篇文章是我之前一门通识课所布置的作业，今天闲的没事就想水一篇文章。\n小石我纵横现代简中互联网多年，对如今的网络文化也有一定的思考，借着通识课作业的契机一并谈谈我对当今网络抽象话的了解。\n中国后现代主义与网络亚文化的发展 以“抽象文化”为例 近年来，随着网络社交平台和短视频行业的发展，我们越来越不难注意到，有这样一类越来越频繁浮现的群体。他们往往说着荒诞又难以理解的话语，洒脱地嘲讽或攻击一些公众形象，同时又无时不刻进行着自我矮化。这类群体在后疫情时期越发壮大逐渐从网络世界的边缘浮现至仅次于主流文化的亚文化地位。在理解了后现代主义和解构主义后，我们可以说这类“抽象文化”的诞生和扩张正是后现代主义思潮在当今中文网络世界的具体表现之一。\n后现代主义一词在法国哲学家利奥塔出版了《后现代状态》一书后正式出道，它是一种基于对西方现代社会进行反思和批判而形成的文化思潮。而其核心理论之一便是宏大叙事的消亡。宏大叙事被认为是现代性的一种体现，是一种使特定意识形态世界观乃至价值观正当化的趋势，也是一种对事物运行规律和人类历史进程的宏观解释。但后现代主义主张对本质的否定和对非理性的推崇，强调多元性、差异性，反对同一性，并具有不确定性、分裂性、解构性及戏谑性等特点。而解构主义则是由法国哲学家德里达提出的，其原本的主张是对中心主义的一种批判，是破坏有中心的二元对立状态，而在今天，解构一词作为一种行为可以用于任何对象和场合，成为了后现代主义中的一环 。\nJean-Francois Lyotard\nJacques Derrida 为什么说目前网络抽象文化的扩张是中国后现代主义的具体表现呢？ 首先抽象文化本身仅仅只是一个指代，其本身并没有具体的定义，因为其本身就是网络去中心化的产物。这批亚文化的创作者们在17,18年左右伴随着李赣和孙笑川之流的直播间而诞生，但值得注意的是【孙笑川】本身并不是该亚文化的定义，它只是抽象文化的一个符号。而抽象文化的符号是无穷无尽的，因为其本身就是一种会无序扩张的社会模因。我在这里举一些最近抽象文化的新网络符号，比如说“yy丁真”系列；抽象小卖部系列；asoul女团；你说的对，但原神是一款XXX系列；东北往事；柯洁直播间等等，与之类似的还有油管的xqc，Ishowspeed，veibae等主播的直播间。抽象文化的群体很喜欢对一些互联网上的土味视频进行解构和二次创作，比如上述的抽象小卖部和东北往事等视频，其原本只是类似于通过卖丑，猎奇等行为换取播放量的视频，但在抽象文化的二次塑形中爆发了前所未有的生命力，原本的猎奇被视为荒诞的艺术，各类卖丑整活的行为也被视为一种对社会规训下的现实的反抗。\n安迪沃霍尔曾说，在未来，每个人都能出名15分钟。 因此，每个人也都可能被吸纳进抽象文化的符号中，因为当你进入了这个飞速迭代的网络世界后，发掘和被消费是在一个很短的周期内被完成的，一个梗，一个meme的生命力是很短暂的，尽管如此它们却可以在如此短的时间中扩张至互联网的每一个角落。但人们迫切地需要新的故事和梗来娱乐和消费，因此这种符号的产生就和人工智能训练集和产出内容一样，无时不刻不在自我迭代和吸收新的叙事。\n后现代主义在这其中中起到了推波助澜的作用。 一方面，后现代主义中的解构化、碎片化和去中心化等因素助推了抽象文化滋生。同时因为当今包含宏大叙事的现代主义在中国仍占据主导地位，对事物的评判仍保有一个中心化的标准，这正是抽象文化理所应当存在的土壤。\n与早年qq空间的杀马特之流不同，抽象文化本身的特点就是对传统鄙视链的彻底摧毁。\n曾经的杀马特文化有各式各类的家族，不同家族之间等级严明，在家族中的地位甚至与你加入的时间有关。**其本质与其说是对资本社会的反抗不如说是通过建立另一个帝国以此逃避原有的社会秩序。**但抽象文化圈却是其完全相反的另一面，比如在百度贴吧中一个人资历可以通过铭牌显示出来，如果入吧的时间早，发言帖子多会增加自己的经验从而提高在本吧的等级。而孙笑川吧中总会出现“黄牌赶紧给绿牌磕一个”这样的话术（黄牌等级高，绿牌等级低）。通过这样完全颠倒的权力体系说明了抽象文化的对鄙视链结构的否定。与之类似的，还有丁真的爆火。在21年初官方为了宣传少数民族和扶贫工作仅仅因为丁真的纯真笑容便将这位学历连小学都没有的文盲聘请至国企工作同时大肆宣传将其捧成了一个网红。大部分网民对此是愤慨且否认的，但批评并不能阻止这样的事发生，因此在后期他们选择将丁真彻底解构，如同第二个孙笑川一样，丁真也成为了抽象文化的符号，网民们肆无忌惮地发表丑化丁真的表情包，将一切他们认为由于官方宣传而火爆但德不配位的人称之为XX丁真，如赛博丁真，滑雪丁真等等。这体现了抽象文化的反权威性和多元性。\n抽象文化也有着和所有后现代主义思潮一样的弊病， 鲍德里亚说过：每个共同体的建构是不同的，但解构都是大同小异的 抽象文化下的网民们乐忠于这样的一种解构，乃至于任何事物在他们面前都只是一堆可供娱乐和消费的符号。一个最直接的例子“地狱笑话”这个词原意是笑了就要下地狱，因为其所取笑的对象本身是由于各种意外而发生悲剧的个体，比如侏儒症患者，残疾人，父母双亡等等。但地狱笑话吧却会以此为依据对其取笑，这样的一种解构是超脱道德的，他们会用草莓来嘲笑因生前想吃草莓，最后却因糖尿病而死的“墨茶”，用直升机戏谑科比等等。为所欲为的解构和消解严肃性成了他们唯一的目的，这本身就是荒诞的，同时也让他们失去了严肃讨论的土壤。\n“抽象文化”在[后现代]皮囊下的[现代性] 在这种后现代思潮的混乱扩张中，许多刚接触抽象文化的新网民会由于其现代化的思想，以遵从威权的思考角度盲目跟风，此时复制相关的话术成为了他们彰显自己抽象属性的方式，用这样一种不加以思考的刻奇的方式加入到后现代思潮的狂欢当中。就像维特根斯坦说的“人不是思考了再说话，而只是说话”。在这时抽象文化的后现代属性消失，它成为了现代化的一种延伸。\n中文互联网经历过各种非主流时期，从早年的杀马特时期，火星文时期，到如今的饭圈文化，抽象文化等。尽管他们迟早会被时间吞噬，但抽象文化作为后现代主义思潮在中国的一种具体体现，其本身将永久地改变整个中文互联网以至于改变新一代网民的思考方式。\n","date":"2024-03-03T13:10:42+08:00","image":"http://tuchuang.dendrobiumcgk.chat/pic/db7641dcd583699a45fbb9a138a5679.jpg","permalink":"https://Dendrobium123.github.io/p/%E4%B8%AD%E5%9B%BD%E5%90%8E%E7%8E%B0%E4%BB%A3%E4%B8%BB%E4%B9%89%E4%B8%8E%E7%BD%91%E7%BB%9C%E4%BA%9A%E6%96%87%E5%8C%96%E7%9A%84%E5%8F%91%E5%B1%95%E4%BB%A5%E6%8A%BD%E8%B1%A1%E6%96%87%E5%8C%96%E4%B8%BA%E4%BE%8B/","title":"中国后现代主义与网络亚文化的发展以“抽象文化”为例"},{"content":" 模拟电路 模拟电路是指用来对模拟信号进行传输、变换、处理、放大、测量和显示等工作的电路。它主要包括放大电路、信号运算和处理电路、振荡电路、调制和解调电路及电源。 何为模拟？ 在模拟电路中，电压高低（或电流大小）是模拟了所代表的物理量的变化，例如声音信号，声音被话筒转换成电压时，电压的高低直接反映了音量大小，声音的频率（音调）直接就是电信号的频率，此谓模拟的概念。\n半导体基础 1.本征半导体：无杂质的稳定结构，其本身导电能力差（一般为+4价的硅晶体 其中不同原子的电子会形成共价键 载流子浓度低 易受温度影响 2.何为载流子？ 脱离共价键的电子称为自由电子（negative 原先的空缺位称为空穴（positive 方便数学处理，将空穴视为一种粒子，因此可与自由电子称为载流子 3.杂质半导体（在本征半导体中掺杂+5价元素和+3价元素 N型半导体：多数载流子为自由电子（掺杂5价元素磷，施主原子—\u0026gt;PN结构中为➕ P型半导体：多数载流子为空穴（掺杂3价元素硼，受主原子—\u0026gt;PN结构中为➖ 4.PN结（单向导电性的原因 本质原因（2 stages 扩散运动（多子参与）：参杂的交接面的剧烈浓度差导致，作用后，P区与N区交界面饱和，载流子不再扩散，中间部分称为耗尽层。 高掺杂—\u0026gt;耗尽层宽度变窄 低掺杂—\u0026gt;耗尽层交宽 多子意义为大部分载流子 漂移运动（少子参与）：扩散运动后，耗尽层不是一个电中和的状态，因此会有內电场，从而在內电场的作用下，少子受电场力作用产生的漂移运动 P区自由电子飘向N区，N区空穴飘向P区，最终参与扩散运动的多子数等于参与漂移的少子数，达到动态平衡，PN结由此产生。 少子意义为少部分载流子 5.单向导电性（半导体存在意义 P+正电，N为负电，电场被削弱，PN结导通 正向导通时，因接触电场的存在，将会在结上形成一固定降压，硅PN结降压一般为0.6V左右，为了好算直接按0.7V计算（0.7必定够用~） 正向导通时—\u0026gt;耗尽层变窄—\u0026gt;扩散运动加剧，多子运动浓度高—\u0026gt;扩散电流上升，从而导通 N加负，P加正（反向电压—\u0026gt;截止 耗尽层变大—\u0026gt;内建电场增强—\u0026gt;利于漂移运动—\u0026gt;扩散现象减弱—\u0026gt;漂移电流减少，从而截止 6.PN结的反向击穿 高浓度掺杂—\u0026gt;齐纳击穿 耗尽层窄，从而很小的反向电压就能击穿 低浓度掺杂—\u0026gt;雪崩击穿 耗尽层宽，需要较大电流才能击穿（由于载流子是以类似链式反应的速率1撞10，10撞100的效率反向运动，类似雪崩，因此被称为雪崩击穿 两种击穿都会产生大量的热，从而损坏元器件 二极管 硅管，导通电压 0.6～0.8v\n锗管，导通电压 0.1～0.3v\n​\t伏安特性曲线\n整流作用\n整流二极管的原理是利用PN结的非线性特性，在正向偏置下允许电流通过，在反向偏置下阻止电流通过。这使得整流二极管可以用于电路中的整流（将交流信号转换为直流信号）和电流保护等应用\n二极管等效电路 二极管微变等效电路 静态工作点：二极管添加直流偏置，此时在伏安特性曲线上所对应的点为静态工作点，此时可将二极管等效为一个动态电阻 公式 稳压二极管 硅管反向击穿时，在一定反向电流范围内，可表现出稳压特性 要保证在一定功率下工作，超出该功率就会爆炸 ","date":"2024-03-01T21:56:02+08:00","image":"http://tuchuang.dendrobiumcgk.chat/pic/微信图片_20240303141619.jpg","permalink":"https://Dendrobium123.github.io/p/%E6%A8%A1%E6%8B%9F%E7%94%B5%E5%AD%90%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/","title":"模拟电子技术笔记"},{"content":"纪念一下terraria大师模式的通关 ​\t虽然之前就知道terraria有四种职业玩法，但从来没试过只用一种职业搭配通关游戏，因为这个游戏的自由度太高了，在没有了解功略的情况下很难自发有意识地控制自己的套装搭配，我想大部分人玩这个游戏都是所谓的散人套装吧。不得不说，分工明确的开荒确实能提高不少效率，在一昧的战斗之外，我也是第一次发现了建筑的乐趣，来看看我造的小家吧！\n我造的小家 一些内饰 这次玩的时候不管是跟npc买还是从各种地牢和洞穴拆，总之弄了超多的画~~ 一些外景 这次跟视频学了一下造鸟居和小桥，我只能说雀食好看\n最后还有我们四人的大合影！ “我见证了一位星子的诞生，是的，一位星子”\n“星子的诞生使这个世界开始动摇”\n“星子杀掉了那只夜晚中的可怖眼球”\n“星子斩断了腐化之地的那条巨大的虫子”\n“星子绞碎了那猩红之地中大脑的幻想”\n“星子碾碎了那暴君之骨，让地牢重见天日”\n“我指引星子来到地狱，让他献祭出世界之墙”\n“古老的光明与黑暗之魂已被释放”\n“星子敲碎了那危险是祭坛，挖掘那些不曾拥有过的矿物”\n“这将是一个恐怖的夜晚……你感到来自于大地的震动……你感觉周围的空气越来越冷……”\n“地面那巨大的机械蠕虫以一种奇怪的姿势停下，天空中的那对双眼一直注视着什么，寒冷的机械骨骼包围住了一个人”\n“星子来到丛林，来寻找那粉色的花苞”\n“我听到了一声刺耳的尖叫，是那个古老的花朵的声音” “星子向我告别，或许他很难再回来”\n“我听到了石头坠落的声音，神庙中的守护者轰然倒塌”\n“我注视着地牢，从白昼看到黑夜，地牢上方闪耀出奇怪的光芒” “天界生物已入侵”\n“星子斩断着那四根天界之柱，拿到天界碎片，合成出那来自天界一般的武器”\n“我感到视线越来越暗，来自那位不可一世的神明，而那不可一世的神明即将降世，我提醒着星子，星子却说他早有准备”\n“天空化为黑暗，四周变得昏沉，在一个耀眼的光芒中，那位神明，降临于泰拉大陆上”\n“我注视着他们的战斗，很快，我瞪大双眼，看到了我这辈子都不曾想象过的景象”\n“神明歪着头说到：\u0026lsquo;你并不是神，但你有着神一般的光芒，你杀死了我，而你的征途却不止于此。\u0026rsquo;”\n“神明死亡，而星子，化为了真正的星。”\n末尾的文字来源b站up主雁老师\n","date":"2024-02-24T20:46:50+08:00","image":"http://tuchuang.dendrobiumcgk.chat/pic/cover terraria.jpg","permalink":"https://Dendrobium123.github.io/p/%E6%88%91%E5%81%9A%E4%BA%86%E4%B8%80%E4%B8%AA%E5%BC%82%E4%B8%96%E7%95%8C%E7%9A%84%E6%A2%A6/","title":"我做了一个异世界的梦"},{"content":"我只想说，做blog好难，尤其是对我这种毫无经验的若至来说 markdown语法现在也没研究明白，不知道要怎么弄\n第一次发博客就随便放两张我们胡桃的照片好了，啊~真可爱啊。\n","date":"2024-02-23T15:46:50+08:00","image":"http://tuchuang.dendrobiumcgk.chat/pic/cover2.jpg","permalink":"https://Dendrobium123.github.io/p/hello-world/","title":"第一篇博客"},{"content":"突然翻到了以前高三整理的文档，那个时候痴迷于西西弗斯和存在主义，也许有时候我的想法已经在不知不觉间被这种哲学思想所影响。\n我还记得去年23年的6月几号来着（我给忘了，我受力王邀请去莲花路吃回转寿司，那天吃完饭后我们几个一边散步一边聊天，似乎两三个钟头把小半个莘庄都给逛完了，力王和段带我灵活地穿梭于那几条对他们来说无比熟悉对我却略显陌生的小道。段离开后，我又和力王骑着共享单车四处溜达，从过往回忆到如今生活经历，从哪个女孩好看到哲学意识形态。我问力王“地铁一号线什么时候关闭？”力王回答我说在双休日可以运营至23点，我没做思考便记下了。\n而当我来到莲花路地铁站时却被通知最后一班富锦路方向的列车已经离开，站点马上要停运了。\n我突然意识到，坏了，这里距离学校有接近25公里路程呢！嘿，天呐，我该怎么办才好？\n忘了说了，当时的第二天我需要在早晨6点30在学校的某个门口准时登上发车前往闵行航天研究院实习的校巴，我当时还想着晚上早点入睡呢！\n怎么办？打车？我一看打车的报价，接近100多人民币，不不不，我本来就是因为力王请客吃饭才赶来的，如果这会打车岂不是要我多出一份莫名其妙的饭钱吗？不，不行。\n那，骑共享单车？也许这是个好主意？我一看地图软件的预估时间，接近2个小时，我想：两个小时，现在是10点出头（也许是这个时间），这么看来回去也不过12点多而已，可能是个比较好的选择相比于打车？\n我扫了车，沿着地铁路线开始骑行，我当时的心态其实并没有那么多的怨气，我是这样想的，这不是一次夜骑上海的机会吗，你见过夜晚的上海吗？我不是指那种充满打了鸡血的年轻人蹦迪的夜生活上海，而是属于普通人的，一个平常上下班时可能有很多汽车拥堵而错过沿途风景的上海，我相信不会有人无聊到在各种高架桥上度过上海的夜生活。\n我骑啊骑。心情从原来的焦虑逐渐变得平缓，先是沿着地铁路线骑，然后跟随导航进入大马路，路过各种小区和门口的商铺，骑的口渴了就下来找个全家买瓶矿泉水，10:40左右的时候各种小区商品房的灯还熙熙攘攘地亮着，随后逐渐变的黑暗。我路过1号线的地铁口，远远看到地铁站的灯光本来还有一丝侥幸想坐个地铁，骑近一看卷帘门都拉上了，我看我还是慢慢骑吧。晚上的上海公路其实还蛮热闹的，有类似测绘员一样的工作人员会拿着经纬仪一样的仪器不知道在做什么的，也有给路面磨淡的标识重新上漆修复的，还有开着柏油车给破损的路面重新上沥青的，这些事件在平时根本见不到吧，我当时越来越觉得，也许今天这个拍脑袋的决定搞不好是个很有意思的选择。我路过长宁区古北的某条渡过苏州河的高架桥时，我一开始没有走桥，结果被苏州河挡住了去路，当我回头原路返回大桥入口时，我看到旁边的几家酒吧门口居然有几个老头盘腿坐在路边，我还以为是和尚在打坐。\n后面的事我有点记不大清了，我只记得大渡河路好长好长好长，明明坐地铁的时候一下就坐过去了，但骑行的时候却超级折磨，导航不停地说还有5km，还有2km\u0026hellip;在普陀区和宝山区的交界时候还给我导航到一个建筑工地里了，后面又给我导航到一个地下隧道，那个时候已经接近1点了，我也处于一种迷迷糊糊的状态，我记得我还在宝山区一块没怎么开发的地上见到了类似大桥的桥墩一样的建筑，好吧，超级奇妙的感觉。\n直到最后回到学校，已然到了凌晨2点，结果发现我的室友们居然没一个在睡觉，很强。\n之所以相隔接近一年才记录这件事情，纯粹是因为我懒，是因为突发奇想想翻以前高中用的讯飞语记，结果翻到了之前记录的各种句子，看到那句\n“穷尽现在不欲其所无，穷尽其所有重要的不是生活的最好，而是生活得最多。\n没有任何一种命运是对人的惩罚，只要竭尽全力去穷尽它就应该是幸福的 。”\n","date":"0001-01-01T00:00:00Z","image":"http://tuchuang.dendrobiumcgk.chat/pic/image-20240517233703783.png","permalink":"https://Dendrobium123.github.io/p/%E7%AA%81%E7%84%B6%E7%9A%84%E6%83%B3%E6%B3%95/","title":"突然的想法"}]